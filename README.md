# XAPR

We introduce a framework that can predict error resilience of GPU code using its CPU counterpart without implementation of the GPU code. Our framework is based on two insights: Error resilience of GPU code is a function of micro-architecture agnostic program properties; We can use statistical models to learn the correlation between program properties and GPU code resilience.

Application resilience is different across di erent platforms. However, programs of the same algorithm running on di erent platforms can be characterized by common properties that are microarchitecture-independent and architecture-independent and inherent to the algorithm. Motivated by the above intuition, we can collect algorithm properties from CPU implementation to characterize the GPU implementation to further gain insight into resilience of the GPU implementation.

# Feature Design and Construction 

* Please refer to https://github.com/HPCCS/PARIS for feature construction on the first 30 features of the feature vector. The remaining 7 features are extracted using the following tools. 

- Thread Block Size: We do not count thread block size, we encourage programmers to project the number of thread block size they suppose to use for the under-development GPU program.
- The average number of times a register is consumed after the last register write: Using MICA (https://github.com/boegel/MICA), a tool built on Intel Pin kit for collecting microarchitecture-independent workload characteristics.
- Number of block page: Using MICA.
- 4 GPU resilience-correlated features: Bank-conflict, Memory-coalescing, Branch-divergence, and ILP rate. We develop a trace-analysis tool to analyze dynamic execution trace to count the four features. 

* GPU resilience-correlated features

- Using the dynamice instruction trace generated by LLVM-Tracer (https://github.com/ysshao/LLVM-Tracer) as input, the program under ./4_GPU_features/ generates an array of 4 fields correlated to the 4 GPU resilience-correlated features.  

- Using the same way described in https://github.com/HPCCS/PARIS, we can construct a feature vector of 37 features for each GPU code. 

# Label Construction

* We use REFINE (https://github.com/ggeorgakoudis/REFINE) to do random fault injection into CPU computation kernel. We modify SASSIFI to enable the modified version to perform random fault injections into specified GPU kernels (https://github.com/HPCCS/SASSIFI-X).

* For each GPU kernel, we can construct a label vector of size 3, mapping to three fault manifestation rates. 

# Training and Testing

* Our dataset has 50 pairs of CPU and GPU code. We use 40 pairs for training and 10 pairs for testing. 

* The feature array for training is [40,37], the label array for training is [40,3]; the feature array for testing is [10,37], the label array for testing is [10,3].

* We use the transfer learning under ./Transfer_Learning_Prediction/ for training and predicting. 

# Prediction Model

* The input to the prediction model is the input used by the prediction model in https://github.com/HPCCS/PARIS and the feature array for training of [40,37], the label array for training of [40,3]; the feature array for testing of [10,37], the label array for testing of [10,3].

* We run the prediction model for one time to predict three fault manifestation rates all together. 
